![](https://github.com/phatakshaunak/Springboard-Data-Science/blob/master/Capstone%20Project%20%233/Readme%20Files/cover_toxic_comment.png)
# **Toxic Comment Classifier** #
*Advancements in technology have made it easier for people to communicate with each other globally owing to the presence of various social media platforms such as Facebook, Twitter and many others. An example of the amount of people online, Facebook has the largest user base of 2.4 billion on its platform. The unfortunate downside of this ease in interacting with each other is the increase of online abuse and cyberbullying. Manually detecting such behavior is cumbersome due to the scale of the data. Natural Language Processing (NLP) is an important tool to be used to automate this task. The goal of this project is to build a toxic comment classification model utilizing the tools in NLP*\
\
The notebook used for this work can be located [here](https://github.com/phatakshaunak/Springboard-Data-Science/blob/master/Capstone%20Project%20%233/Notebooks/Toxic_Comment_Classifier.ipynb)

## 1. Data

The data[https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data] for this project was provided by Conversation AI as part of a Kaggle competition. It contained ~160,000 comments tagged with six labels, viz. toxic, severe toxic, obscene, threat, insult and identity hate. This is a multi-label classification problem as comments can have multiple labels.

## 2. Data Wrangling / EDA / Text Preprocessing

The table below indicates a highly imbalanced dataset with most comments being unlabeled or 'safe'. This problem will be explored later with resampling techniques like SMOTE.  
\
![](https://github.com/phatakshaunak/Springboard-Data-Science/blob/master/Capstone%20Project%20%233/Readme%20Files/label_dist.png)  
\
Further, some comments have multiple labels. The chart below indicates this distribution apart from which 143,346 comments are labeled safe. The horizontal axis represent the number of labels.  
\
![](https://github.com/phatakshaunak/Springboard-Data-Science/blob/master/Capstone%20Project%20%233/Readme%20Files/cat_bar_6.png)  
\
It was also observed that atleast 90% comments (100% for severe toxic) with the other five labels had also been labeled as toxic. The top label combinations below shows that the label toxic is associated with 7 out of the top 10 labels.  \
![](https://github.com/phatakshaunak/Springboard-Data-Science/blob/master/Capstone%20Project%20%233/Readme%20Files/label_combinations.png)   
\
Text pre-processing involved applying a number of standardization techniques such as:  
\
![](https://github.com/phatakshaunak/Springboard-Data-Science/blob/master/Capstone%20Project%20%233/Readme%20Files/text_cleaning_pipe.png)  

## 3. Word Representation and Modeling

Frequency based methods such as Bag of Words and TF-IDF as well as word embedding models such as Word2Vec and GloVe were used to create numeric vectors for each comment to be used in a machine learning classifier. Resampling the minority class with SMOTE was explored to check for model improvements.
The algorithms used include Mutlinomial Naive Bayes (MNB), Logistic Regression (LG) and Light Gradient Boosting (LGBM). Metrics used to evaluate modeling performance included AUC score, F1-score and hamming loss.
Six independent classifiers were created for each toxicity label. Other methods that can be explored later include label powerset and classifier chains which can take into account label correlations.

The table below shows the metrics using frequency methods without resampling. LG and LGBM outperformed MNB. LG was a better choice than LGBM as it did not overfit as much as the latter. Bag of Words and TF-IDF had a similar performance, although LG with TF-IDF had the optimal performance.  
\
![](https://github.com/phatakshaunak/Springboard-Data-Science/blob/master/Capstone%20Project%20%233/Readme%20Files/freq_wo_resamp.png)  
\
The table below shows the same results as above but has data resampled with SMOTE. All models exhibited overfitting shown by the differences in the AUC and F1 scores for training and test sets. 
\
![](https://github.com/phatakshaunak/Springboard-Data-Science/blob/master/Capstone%20Project%20%233/Readme%20Files/freq_w_resamp.png)  
\
Next, results for word embeddings without resampling are shown below. Comment vectors were generated by averaging the word vectors. For words not present in the pre-trained model vocabulary, an average model vector was created to represent such words. These results did not show any significant improvements over frequency based mthods. The F1-scores were also slightly lower than the Bag of Words / TF-IDF models.  
\
![](https://github.com/phatakshaunak/Springboard-Data-Science/blob/master/Capstone%20Project%20%233/Readme%20Files/word_emb_wo_resamp.png)  
\
Applying resampling with word embeddings again involved overfitting for all the tested models. Looking at the vocabulary for the pre-trained models, it was observed that 65% and 47% of unique words of the comment corpus were not present in the Word2Vec and GloVe models respectively. This may be a potential cause of no improvements using these embeddings over frequency based methods.

## 4. Conclusions and Future Work

This project aimed at creating a multi-label classification model for toxic comments. Utilizing SMOTE resampling to handle label imbalances led to overfitting across all models tested. Out of all the word representations and machine learning models, Logistic Regression with TF-IDF and no SMOTE resampling had the optimal performance. Word embeddings did not improve over bag of words / TF-IDF potentially due to the absence of many comment corpus words in the pre-trained Word2Vec and GloVe models.  
\
The project can be extended in a number of ways such as:
* Create comment vectors using sub-word information from models such as FastText. This may better handle out of vocabulary words as well as spelling mistakes
* Apply deep learning algorithms
* Use other multi-label modeling techniques such as label powerset and classifier chains to incorporate label correlations.

